{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7004,"status":"ok","timestamp":1684658344996,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"kmqC_sgU7fe3","outputId":"3a1ef728-d768-48ea-ca43-371a14259e28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.105-py3-none-any.whl (586 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.5/586.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Collecting sentry-sdk (from ultralytics)\n","  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","Installing collected packages: sentry-sdk, ultralytics\n","Successfully installed sentry-sdk-1.23.1 ultralytics-8.0.105\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5070,"status":"ok","timestamp":1684658905919,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"kkOA_prF714Q","outputId":"c7f7e4c1-1bd1-46cf-9c6e-fee14bda17cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"]}],"source":["import os\n","import shutil\n","import random\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23345,"status":"ok","timestamp":1684658886463,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"X8_eObTb8AKT","outputId":"b059307e-f95d-458c-e9f1-f0fd89022793"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXOiKRdf8U_J"},"outputs":[],"source":["train_path_img = \"./Dataset/images/train/\"\n","train_path_label = \"./Dataset/labels/train/\"\n","val_path_img = \"./Dataset/images/train/\"\n","val_path_label = \"./Dataset/labels/train/\"\n","#test_path = \"./yolo_data/test\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIEprdh486d8"},"outputs":[],"source":["def train_test_split(path,neg_path=None, split = 0.2):\n","    print(\"------ PROCESS STARTED -------\")\n","\n","\n","    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n","    \n","\n","    print (f\"--- This folder has a total number of {len(files)} images---\")\n","    random.seed(42)\n","    random.shuffle(files)\n","\n","    test_size = int(len(files) * split)\n","    train_size = len(files) - test_size\n","\n","    ## creating required directories\n","\n","    os.makedirs(train_path_img, exist_ok = True)\n","    os.makedirs(train_path_label, exist_ok = True)\n","    os.makedirs(val_path_img, exist_ok = True)\n","    os.makedirs(val_path_label, exist_ok = True)\n","\n","    \n","    ### ----------- copying images to train folder\n","    for filex in tqdm(files[:train_size]):\n","      if filex == 'classes':\n","          continue\n","      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n","        \n","    \n","\n","    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n","    \n","    if neg_path:\n","        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n","        for filex in tqdm(neg_images):\n","            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n","            \n","        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n","    \n","        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n","    \n","\n","\n","    ### copytin images to validation folder\n","    for filex in tqdm(files[train_size:]):\n","      if filex == 'classes':\n","          continue\n","      # print(\"running\")\n","      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n","    \n","    print(\"------ TASK COMPLETED -------\")\n","\n","## spliting the data into train-test and creating train.txt and test.txt files\n","# train_test_split('/content/drive/MyDrive/custom_notebooks/yolo_data/')\n","\n","### for label_tag\n","#train_test_split('/content/gdrive/MyDrive/AI/dataset/') ### without negative images\n","# train_test_split('./data/','./negative_images/') ### if you want to feed negative image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5337,"status":"ok","timestamp":1684659538853,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"6fkbZpEQ-oQx","outputId":"2a7cf5d7-5bf4-46db-c271-7d34bdb2448d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.105 🚀 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"]}],"source":["import ultralytics\n","ultralytics.checks()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lv6dSv7tZAhp"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fToCcSRRaruy"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"D-zvkmMejfW4"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372087,"status":"ok","timestamp":1684660020603,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"U2lGfGjS-4Of","outputId":"d3bd6ba3-b153-47c8-83ab-54e8073bcbf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n","100% 21.5M/21.5M [00:01<00:00, 14.1MB/s]\n","Ultralytics YOLOv8.0.105 🚀 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/gdrive/MyDrive/Dataset/data_classes.yaml, epochs=50, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/gdrive/MyDrive/Dataset, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/gdrive/MyDrive/Dataset/train12\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 146MB/s]\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n","Model summary: 225 layers, 11136761 parameters, 11136745 gradients\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/gdrive/MyDrive/Dataset/train12', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n","100% 6.23M/6.23M [00:00<00:00, 379MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/labels/train.cache... 61 images, 0 backgrounds, 0 corrupt: 100% 61/61 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/labels/train.cache... 61 images, 0 backgrounds, 0 corrupt: 100% 61/61 [00:00<?, ?it/s]\n","Plotting labels to /content/gdrive/MyDrive/Dataset/train12/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/Dataset/train12\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      2.14G      2.757      4.459      2.404         49        640: 100% 8/8 [01:20<00:00, 10.11s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:10<00:00,  2.66s/it]\n","                   all         61        274    0.00219      0.116    0.00168   0.000609\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50      2.19G      2.703      3.947      2.377         37        640: 100% 8/8 [01:09<00:00,  8.73s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  2.46it/s]\n","                   all         61        274      0.148     0.0601     0.0508      0.026\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50      2.19G      2.625      3.366      2.264         47        640: 100% 8/8 [01:16<00:00,  9.55s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  2.03it/s]\n","                   all         61        274      0.185        0.2      0.207       0.11\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50      2.18G      2.431      2.704      2.109         46        640: 100% 8/8 [01:11<00:00,  8.89s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.64it/s]\n","                   all         61        274      0.392      0.393       0.35      0.186\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","  0% 0/8 [00:15<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 394, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/model.py\", line 371, in train\n","    self.trainer.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py\", line 192, in train\n","    self._do_train(world_size)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py\", line 311, in _do_train\n","    for i, batch in pbar:\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1178, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/data/build.py\", line 38, in __iter__\n","    yield next(self.iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n","    self.not_empty.wait(remaining)\n","  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n","    gotit = waiter.acquire(True, timeout)\n","KeyboardInterrupt\n","^C\n"]}],"source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/gdrive/MyDrive/Dataset/data_classes.yaml epochs=50 imgsz=640 batch=8 project=/content/gdrive/MyDrive/Dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9J84JYAxFVA6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14722,"status":"ok","timestamp":1684655354298,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"p3pni6K3GbeJ","outputId":"ee58969d-f20a-4e36-8191-9a14401d0c70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.105 🚀 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11126745 parameters, 0 gradients\n","\n","image 1/9 /content/gdrive/MyDrive/Dataset/test/Compressor_002.jpg: 480x224 1 compressor, 1 base_plate, 2 wires, 65.7ms\n","image 2/9 /content/gdrive/MyDrive/Dataset/test/Compressor_005.jpg: 224x480 1 compressor, 1 base_plate, 3 wires, 62.9ms\n","image 3/9 /content/gdrive/MyDrive/Dataset/test/Compressor_006.jpg: 480x224 1 compressor, 1 base_plate, 2 wires, 8.8ms\n","image 4/9 /content/gdrive/MyDrive/Dataset/test/Compressor_016.jpg: 480x384 1 compressor, 2 base_plates, 2 wires, 70.7ms\n","image 5/9 /content/gdrive/MyDrive/Dataset/test/Compressor_022.jpg: 384x480 1 compressor, 1 base_plate, 1 wire, 63.6ms\n","image 6/9 /content/gdrive/MyDrive/Dataset/test/Compressor_024.jpg: 480x384 1 compressor, 1 base_plate, 3 wires, 11.9ms\n","image 7/9 /content/gdrive/MyDrive/Dataset/test/Compressor_044.jpg: 384x480 1 compressor, 2 base_plates, 1 wire, 12.9ms\n","image 8/9 /content/gdrive/MyDrive/Dataset/test/Compressor_057.jpg: 384x480 1 compressor, 1 base_plate, 4 wires, 10.6ms\n","image 9/9 /content/gdrive/MyDrive/Dataset/test/Compressor_059.jpg: 480x384 1 compressor, 1 base_plate, 2 wires, 11.9ms\n","Speed: 2.2ms preprocess, 35.4ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 480)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"]}],"source":["!yolo task=detect mode=predict model=/content/gdrive/MyDrive/Dataset/train11/weights/best.pt conf=0.25 source=/content/gdrive/MyDrive/Dataset/test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3qo8-hYfDlgr","outputId":"e8c9946f-feb0-4d81-fa5b-ac8d38d1c6d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.105 🚀 Python-3.10.11 torch-2.0.1+cu118 CPU\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/gdrive/MyDrive/Dataset/data_classes.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n","Model summary: 225 layers, 11136761 parameters, 11136745 gradients\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/labels/train.cache... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/labels/train.cache... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train2/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/5         0G      2.736      4.388      2.365        115        640: 100%|██████████| 4/4 [03:24<00:00, 51.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:56<00:00, 28.22s/it]\n","                   all         61        274    0.00218      0.125    0.00141   0.000585\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/5         0G      2.689      4.091      2.312        100        640: 100%|██████████| 4/4 [03:06<00:00, 46.73s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:56<00:00, 28.33s/it]\n","                   all         61        274    0.00424      0.243    0.00827    0.00347\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/5         0G      2.632      3.602      2.335        100        640: 100%|██████████| 4/4 [02:59<00:00, 44.86s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:54<00:00, 27.48s/it]\n","                   all         61        274      0.279     0.0984      0.132     0.0697\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","  0%|          | 0/4 [00:00<?, ?it/s]"]}],"source":["from ultralytics.yolo.engine.model import YOLO\n","\n","model = YOLO(\"yolov8s.pt\")\n","model.train(data=\"/content/gdrive/MyDrive/Dataset/data_classes.yaml\", epochs=10)\n","results = model.predict('/content/gdrive/MyDrive/Dataset/test/Compressor_002.jpg', save=True, save_txt=True)\n","\n","for result in results:\n","   boxes = result.boxes  # Boxes object for bbox outputs\n","   masks = result.masks  # Masks object for segmenation masks outputs\n","   probs = result.probs  # Class probabilities\n","   print(boxes)\n","   print(masks)\n","   print(probs)\n","\n","\n","boxes = results[0].boxes\n","box = boxes[0]  # returns one box\n","box.xyxy\n","boxes.xyxy  # box with xyxy format, (N, 4)\n","boxes.xywh  # box with xywh format, (N, 4)\n","boxes.xyxyn  # box with xyxy format but normalized, (N, 4)\n","boxes.xywhn  # box with xywh format but normalized, (N, 4)\n","boxes.conf  # confidence score, (N, 1)\n","boxes.cls  # cls, (N, 1)\n","boxes.data  # raw bboxes tensor, (N, 6) or boxes.boxes ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"elapsed":15849,"status":"error","timestamp":1684625412306,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"Uq0xJhcWIdQf","outputId":"f0cf39e2-17c1-42f7-8853-11d255945e6f"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-446c6f87696b>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m   \u001b[0;31m# box with xyxy format, (N, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxywh\u001b[0m   \u001b[0;31m# box with xywh format, (N, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxyn\u001b[0m  \u001b[0;31m# box with xyxy format but normalized, (N, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'boxes'"]}],"source":["\n","import cv2\n","from ultralytics import YOLO\n","from ultralytics.yolo.utils.plotting import Annotator\n","\n","\n","#img=/content/runs/detect/predict/Compressor_002.jpg (\"/content/gdrive/MyDrive/Dataset/test/Compressor_002.jpg\")\n","#img1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","results =!yolo task=detect mode=predict model=/content/gdrive/MyDrive/Dataset/train10/weights/best.pt conf=0.55 source=/content/gdrive/MyDrive/Dataset/test/ \n","\n","\n","\n","\n","\n","        \n","for result in results:\n","    # detection\n","    result.boxes.xyxy   # box with xyxy format, (N, 4)\n","    result.boxes.xywh   # box with xywh format, (N, 4)\n","    result.boxes.xyxyn  # box with xyxy format but normalized, (N, 4)\n","    result.boxes.xywhn  # box with xywh format but normalized, (N, 4)\n","    result.boxes.conf   # confidence score, (N, 1)\n","    result.boxes.cls    # cls, (N, 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0uVAXYeHs7T"},"outputs":[],"source":["\n","!yolo task=detect mode=predict model=/content/gdrive/MyDrive/AI/dataset/train/weights/best.pt conf=0.77 source=/content/gdrive/MyDrive/AI/dataset/videos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1684215715405,"user":{"displayName":"Fathima hisa Faiyaz","userId":"13404626100919061545"},"user_tz":-120},"id":"85_npfz3K_Ot","outputId":"bf0ae74d-ab1e-4b02-9eae-1456a92df0cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov8'...\n","fatal: could not read Username for 'https://github.com': No such device or address\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UPK98s9dkIy"},"outputs":[],"source":["\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP2BJzn0tVwDoAsWlbqrxVv","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
